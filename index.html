e<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Surbhi Madan</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.3.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">

<!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Surbhi Madan</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/Surbhi.jpeg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="CV/Surbhi_Madan_CV.pdf" target="_blank">CV</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Work Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#research">Research Interest</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
                    
                    
                    
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#contact">Contact</a></li>
        
                </ul>
            </div>
        </nav>
      
        
<!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content" >
                    <br><br><h2 class="mb-0">
                        Surbhi
                        <span class="text-primary">Madan</span>
                    </h2>
                    <div class="subheading mb-3">
                        Department of Computer Science and Engineering, LASSI Lab, Indian Institute of Technology Ropar, Punjab-140001, India<br>
                        <!-- <a href="mailto:d_kumar@cs.iitr.ac.in">surbhi.19csz0011@iitrpr.ac.in</a> -->
                        Mail Id: surbhi.19csz0011@iitrpr.ac.in
                    </div>
                    <p align="justify" class="lead mb-3" >I am a postdoc researcher at <a href="https://www.nii.ac.jp/en/",target="_blank">National Institute of Informatics</a>, Tokyo, Japan with <a href="https://yamagishilab.jp/", target="_blank">Yamagishi Lab, NII Group</a>. I completed my Ph.D. at LASII Group, Department of Computer Science & Engineering, <a href="https://www.iitrpr.ac.in/", target="_blank">Indian Institute of Technology Ropar,
India</a>, under the supervision of <a href ="https://research.monash.edu/en/persons/abhinav-dhall/", target="_blank">Prof. Abhinav Dhall</a> and <a href="https://www.ramsubramanian.net/", target="_blank">Prof. Ramanathan Subramanian</a>. Before joining Ph.D., I have completed my master‚Äôs degree 
                        from <a href="https://nith.ac.in/", target="_blank">National Institute of Technology, Hamirpur</a>.
                    My research focused on Affective Computing, Human-Computer Interaction,  Physiological Sensing, Computer Vision and Applied Deep Learning.</p>
                        <!--<p class="lead mb-3" align="justify">I'm passionate about relating humans and computers and use that understanding to optimize people's well-being. I perceive humans as an assembly of fat-muscle-bone-water on the hardware level
                             and a bundle of impressions-sensations-emotions-thoughts-actions on the software level. We are made up of carbon (instead of silicon), have mind-brain-hormones 
                             (as opposed to OS-processor-current), and deploy physical-mental-emotional-psychological-mental-spiritual resources (instead of computational resources) in reaction to various situations.</p> -->
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/surbhi-madan-3384b130/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/surbhimadan92"><i class="fab fa-github"></i></a>
                       <a class="social-icon" href="https://www.instagram.com/surbhimadan92/"><i class="fab fa-instagram"></i></a>
                        <a class="social-icon" href="https://www.facebook.com/surbhi.madan.75"><i class="fab fa-facebook-f"></i></a>
                        <a class="social-icon" href="https://scholar.google.com/citations?user=aI7hnU8AAAAJ&hl=en", target="_blank"><i class="fab fa-google"></i></a>
                    </div>
               <!-- </div>
            </section>
            <hr class="m-0" />
            

            <section class="resume-section" id="news">
                <div class="resume-section-content"> -->
    <br><br><hr>    
        <h3 class="mb-3">üî• News</h3>
                <ul class="fa-ul mb-0">
                                        <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2026: Submitted the review for the journal  <a href="https://drive.google.com/file/d/1s6xoeO25VMnIpXAmruSWkBCrOSOTiUnh/view?usp=sharing", target="_blank">Discover Artificial Intelligence</a>.
                    </li>

                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2026: Submitted the review for the journal  <a href="https://drive.google.com/file/d/1vLNqWKc5r18csGVnuQWLEVuVmiw6-nXE/view?usp=sharing", target="_blank">Scientific Reports</a>.
                    </li>

                      <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2026: Reviews submitted for three papers at  <a href="https://fg2026.ieee-biometrics.org/", target="_blank">FG 2026</a>.
                    </li>
                     <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2026: Submitted review for a research paper at  <a href="https://www.computer.org/csdl/magazine/mu", target="_blank">IEEE Multimedia.</a>.
                    </li>

                                       <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Jan 2026: Accepted invitation to be a reviewer at <a href="https://eccv.ecva.net/Conferences/2026/Dates", target="_blank">ECCV 2026</a>.
                    </li>
                                           <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Jan 2026: Received certificate for recognition of my efforts for paper review at <a href="https://drive.google.com/file/d/1cQeCJZtdQTn9bFGIHo9j1TRvcOOQXQuE/view?usp=sharing", target="_blank">IEEE Mutimedia</a>.
                    </li>
                    
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2025: Submitted reviews for a paper at <a href="https://drive.google.com/file/d/1Hr49Q-b_F7nizQBc-Heh2jO2JCrbJPeP/view?usp=sharing", target="_blank">IEEE Transactions on Affective Computing</a>.
                    </li>
<li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Oct 2025: Accepted invitation to be a reviewer for <a href="https://cvpr.thecvf.com/", target="_blank">CVPR 2026</a>.
                    </li>
                    
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Oct 2025: Our paper titled <b>CSGaze: Context-aware Social Gaze Prediction</b> is accepted for the publication in <b>ICVGIP 2025 </b> to be held at IIT Mandi from December 17.
                    </li>
                     <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Sep 2025: Awarded funding under Sythetiq Vision Japan to attend <b> IEEE International Joint Conference on Biometrics (IJCB)</b> 2025 at OSaka Japan. 
                    </li>
                    
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Oct 2025: Became a reviewer of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165369", target="_blank">IEEE Transactions of Affective Computing</a> Journal.
                    </li>
                    <!-- <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Sep 2025: Submitted reviews for a journal paper of <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5165369", target="_blank">IEEE Transactions of Affective Computing</a>.
                    </li> -->
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Aug 2025: Became a reviewer of <a href="https://deepfakes1m.github.io/2025", target="_blank">1M-Deepfakes Detection Challenge</a> of the 33<sup>rd</sup> ACM International Conference on Multimedia (MM 2025).
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        July 2025: Defended Ph.D. Dissertation successfully on 10 July 2025.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2025: Our paper title GEMS: GROUP EMOTION PROFILING THROUGH MULTIMODAL SITUATIONAL UNDERSTANDING is accepted for the publication at  <a href="https://2025.ieeemlsp.org/en/", target="_blank">IEEE MLSP 2025</a>.
                    </li>
                      <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2025: Submitted the reviews for a paper at  <a href="https://drive.google.com/file/d/12cPLsSK-nJLttkfibKrYvTMj_topCmgA/view?usp=sharing", target="_blank">International Journal of Artificial Intelligence in

Education</a>.
                    </li>
                    <!-- <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2025: Became a <a href="https://drive.google.com/file/d/1BaNCJdz7b6-nQLryMelBLPe8DSwVRu1w/view?usp=sharing", target="_blank">reviewer</a> of <a href="https://www.ngndai.mnnit.ac.in/", target="_blank">International Conference</a> on Next-Generation Networks amd Deployable Artificial Intelligence (NGNDAI-2025).
                    </li> -->
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Feb 2025: Our paper titled "Multiview Attention Fusion for Explainable Body Language Behavior Recognition" has been accepted for publication at <a href ="https://ieeexplore.ieee.org/abstract/document/10915548 "> IEEE Transactions on Affective Computing  </a>.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Jan 2025: Our paper title "EEG-based Cognitive Load Estimation of Acoustic Parameters for Data Sonification" is published at <a href="https://ieeexplore.ieee.org/document/10820953">  IEEE Transactions on Cognitive and Developmental Systems    </a>.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2024: Received travel Grant to attend The Fifth Indian Symposium on Machine Learning (IndoML) hosted by the BITS Pilani Goa Campus from December 21-23, 2024.
                    </li>
                    <!-- <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2024: Became a <a href="https://drive.google.com/file/d/1GYG605UdKL1iZCrSZdVD4_UeeuzrdwyG/view?usp=sharing", target="_blank">reviewer</a> of the IEEE 6<sup>th</sup> International Conference on Computational Intelligence and Networks, CINE 2024.
                    </li> -->
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Nov 2024: Our paper titled "Explainable human-centered traits from head motion and facial expression dynamics " is accepted for the publication at <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0313883"> PLOS ONE </a> Journal.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Aug 2024: A paper titled 'Towards Engagement Prediction: A Cross-Modality Dual-Pipeline Approach using Visual and Audio Features' got accepted at The 32<sup>nd</sup> ACM International Conference on Multimedia (MM'24) 28 Oct-01 Nov 2024, Melbourne, Australia.
                    </li>


                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        June 2024: Became a reviewer of the 9<sup>th</sup> International Conference on Computer Vision and Image Processing (CVIP 2024).
                    </li>


                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2023: Played a role as a volunteer at the 14<sup>th</sup> The Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) conference 2023 from 15 - 17 December at IIT Ropar, India.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        July 2023: Our paper titled as MAGIC-TBR: Multiview Attention Fusion for Transformer-based Bodily Behavior Recognition in Group Settings" has been accepted for <a href ="https://www.acmmm2023.org/grand-challenges/">ACM Multimedia 2023 Multimedia Grand Challenges Track</a>.
                    </li>
            
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Dec 2019: Started pursuing Ph.D. at LASII Lab, Computer Science & Engineering Department <a href="https://cse.iitrpr.ac.in//" />IIT Ropar </a> advised by <a href="https://research.monash.edu/en/persons/abhinav-dhall/"/>Prof. Abhinav Dhall</a> and <a href="https://researchprofiles.canberra.edu.au/en/persons/ramanathan-subramanian/"/>Prof. Ramanathan Subramanian</a>. 
                    </li>
                </ul>
<br><br><hr>
<!--       Education     --> 
<!-- <div class="resume-section-content"> -->
            <h3 class="mb-3" id="education">Education</h3>
            <div class="d-flex flex-column flex-md-row justify-content-between mb-1">
                <div class="flex-grow-1">
                <h3 class="mb-0">Indian Institute of Technology, Ropar, Punjab, India</h3>
                <div class="subheading mb-0">Ph.D.</div>
                <div>Computer Science and Engineering</div>
                <p>CGPA: 9.0   <br>
                <b>Supervisor:</b> <a href ="https://research.monash.edu/en/persons/abhinav-dhall/", target="_blank">Prof. Abhinav Dhall</a> and <a href="https://www.ramsubramanian.net/", target="_blank">Prof. Ramanathan Subramanian</a></p>
                </div>
                <div class="flex-shrink-0"><span class="text-primary">December 2019 - July 2025 </span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">National Institute of Technology, Hamirpur, Himachal Pradesh, India</h3>
                    <div class="subheading mb-0">M.Tech.</div>
                    <div>Computer Science and Engineering</div>
                    <p>CGPA: 8.89 <br>
                        <b>Supervisor:</b> <a href="https://portfolios.nith.ac.in/index.php?/nith/rajeev-kumar-", target="_blank">Prof. Rajeev Kumar    </a>
                    </p>
                </div>
            <div class="flex-shrink-0"><span class="text-primary">August 2014 - June 2016</span></div>
            </div>

            <div class="d-flex flex-column flex-md-row justify-content-between">
                <div class="flex-grow-1">
                    <h3 class="mb-0">Uttar Pradesh Technical University Lucknow, Uttar Pradesh, India</h3>
                    <div class="subheading mb-0">B.Tech.</div>
                    <div>Computer Science and Engineering</div>
                    <p>PERCENTAGE: 78.15</p>
                </div>
        <!-- <div class="flex-shrink-0"><span class="text-primary">August 2014 - June 2016</span></div>  -->
            </div>
<br><hr>
<!--      Work Experience      -->
           <h3 class="mb-2" id="experience">Work Experience</h3>
            <!----------------->     
          <!--   <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Work-studentship </h3>
                            <div class="subheading mb-1">Deloitte US-India Offices</div>
                            <!-- <p>sdbhdbdjja</p>  -->
                     <!--    </div> 
                        <div class="flex-shrink-0"><span class="text-primary">August 2023 - January 2024</span></div>
                    </div>
               -->
            <!---------------------->
            <div class="d-flex flex-column flex-md-row justify-content-between mb-2">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Project Researcher (PostDoc)</h3>
                        <div class="subheading mb-3">National Institute of Informatics (NII), Tokyo, Japan</div>
                        <!-- <p>Job description </p>  -->
                     </div>
                    <div class="flex-shrink-0"><span class="text-primary">Aug 2025 - Present</span></div> 
                </div>
            <!---------------------->
                    
            <div class="d-flex flex-column flex-md-row justify-content-between mb-2">
                    <div class="flex-grow-1">
                        <h3 class="mb-0">Assistant Professor</h3>
                        <div class="subheading mb-3">Teerthanker Mahaveer University, Moradabad, Uttar Pradesh, India</div>
                        <!-- <p>Job description </p>  -->
                     </div>
                    <div class="flex-shrink-0"><span class="text-primary">July 2016 - November 2019</span></div> 
                </div> 

<hr>

<!--   Research Interest  -->

<h3 class="mb-3" id="research">Research Interests</h3>
<ul class="fa-ul mb-0">
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Affective Computing and Cognitive Science
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Machine Learning, Deep Learning, and Computer Vision
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Multimodal Information Analysis
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Human Computer Interaction (HCI)
    </li>
    <li>
        <span class="fa-li"><i class="fas fa-check"></i></span>
        Vision Language Models (VLMs)
    </li>
    
</ul>
<br><hr> 

<!------       Publications  ----->
<h3 class="mb-4" id="publications"><span>Publications</span></h3>
<h4 class="mb-4" id="Journal"><span>&#128221; Journal</span></h4>
                <table><tbody>
                    
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>1</b>.&nbsp;</td>
                        <td><img src="assets/img/PLOS.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Monika Gahalawat, Tanaya Guha, Roland Goecke, and Ramanathan Subramanian, "Explainable Human-centered Traits from Head Motion and Facial 
                            Expression Dynamics" PLOS ONE. <b>[SCI, Q1, IF=2.9]</b>
                            <br>					 
                        </td>
                      </tr>
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>2</b>.&nbsp;</td>
                        <td><img src="assets/img/EEG.PNG" width="380" height="140"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            Gulshan Sharma, <b>Surbhi Madan</b>, Maneesh Bilalpur, Abhinav Dhall, and Ramanathan Subramanian, "EEG-based Cognitive Load Estimation of Acoustic Attributes 
                            for Data Sonification" IEEE Transactions on Cognitive and Developmental Systems. <b>[SCI, Q1, IF=5.0]</b>
                            <br>					 
                        </td>
                      </tr>
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>3</b>.&nbsp;</td>
                        <td><img src="assets/img/TAFFC.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Rishabn Jain, Ramanathan Subramanian, and Abhinav Dhall, "Multiview Attention Fusion for Explainable Body Language Behavior Recognition" 
                            IEEE Transactions on Affective Computing. <b>[SCI, Q1, IF=9.6]</b>
                            <br>					 
                        </td>
                      </tr>
                </tbody></table>
<br>
<!-- <h4 class="mb-4" id="Conference"><span>Conferences</span></h4>  -->
  <h4 id="Conference"><span>üìù Conferences</span></h4>                  
                <table><tbody>
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>1</b>.&nbsp;</td>
                        <td><img src="assets/img/Social_Gaze.png" width="420" height="100"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Shreya Ghosh, Ramanathan Subramanian, Abhinav Dhall, and Tom Gedeon, "CSGaze: Context-aware Social Gaze Prediction", The 16th Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP) 
                            Dec 17 - 20, 2025, IIT Mandi, Himachal Pradesh, India.
                            <b>[Accepted]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>2</b>.&nbsp;</td>
                        <td><img src="assets/img/GEMS.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            A. Kataria <b>Surbhi Madan</b>, Shreya Ghosh, Tom Gedeon, and Abhinav Dhall, "GEMS: group emotion profiling
                            through multimodal situational understanding", 35th IEEE International Workshop on Machine
                            Learning for Signal Processing (IEEE MLSP 2025) Aug 31 - Sep 3, 2025 , Istanbul, Turkey.
                            <b>[CORE B | ERA B]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>3</b>.&nbsp;</td>
                        <td><img src="assets/img/MIP.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Shreya Ghosh, Lownish Rai Sookha Sookha, Mudasir Ahmad Ganaie, Ramanathan Subramanian, Abhinav Dhall, and Tom Gedeon, "MIP-
                            GAF: A MLLM-annotated Benchmark for Most Important Person Localization and Group Context
                            Understanding", Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
                            Vision (WACV 2025), Feb 28 ‚Äì Mar 4, 2025, Tucson, Arizona.
                            <b>[CORE A | Qualis B1]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>4</b>.&nbsp;</td>
                        <td><img src="assets/img/MM.png" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            Deepak Kumar, <b>Surbhi Madan</b>, Pradeep Singh, Abhinav Dhall, and Balasubramanian Raman, "Towards Engagement Prediction: A Cross-Modality Dual-Pipeline Approach using Visual and Audio Features", 32nd ACM International Conference on Multimedia (MM'24) 28 Oct-01 Nov 2024, Melbourne, Australia.
                            <b>[CORE A* | ERA A]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>5</b>.&nbsp;</td>
                        <td><img src="assets/img/MAGIC.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Rishabh Jain, Gulshan Sharma, Ramanathan Subramanian, and Abhinav Dhall, "MAGIC-TBR: Multiview Attention Fusion 
                            for Transformer-based Bodily Behavior Recognition in Group Setting", Proceedings
                            of the 31st ACM International Conference on Multimedia (MM‚Äô23), pp. 9526-9530, October 29 -
                            November 3, 2023, Ottawa, Canada.
                            <b>[CORE A* | ERA A]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->
                    
                    <tr valign="top">
                        <td style="vertical-align:top;"><b>6</b>.&nbsp;</td>
                        <td><img src="assets/img/HEAD.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Monika Gahalawat, Tanaya Guha, and Ramanathan Subramanian, "Head matters: explainable human-
                            centered trait prediction from head motion dynamics", Proceedings of the 23rd ACM International
                            Conference on Multimodal Interaction (ICMI 2021), pp. 435-443, October 18-22, 2021, Montreal, Canada.
                            <b>[CORE B | Qualis A2]</b>
                            <br>					 
                        </td>
                      </tr>
                    <!-- ---------      -->

                      <tr valign="top">
                        <td style="vertical-align:top;"><b>7</b>.&nbsp;</td>
                        <td><img src="assets/img/SMART.jpg" width="420" height="300"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Surbhi Madan</b>, Deepak Kumar, and Anamika Agnihotri. "Privacy-Preserving Data Aggregation in Wireless Sensor." 2018 International Conference on System Modeling & Advancement in Research Trends (SMART 2018). 
                            <br>					 
                        </td>
                        
                      </tr>
                      &nbsp;
                      <!-- <tr valign="top">
                        <td style="vertical-align:top;"><b>7</b>.&nbsp;</td>
                        <td><img src="assets/img/CVIP_Final.jpg" width="420" height="200"></td>
                        <td>&nbsp;&nbsp;</td>
                        <td style="vertical-align:top;" align="justify">
                            <b>Deepak Kumar</b> and Balasubramanian Raman. "Speech-based Automatic Prediction of Interview Traits." 2018 International Conference on System Modeling & Advancement in Research Trends (SMART 2018). <b>[IAPR Endorsed ]</b>
                            <br>					 
                        </td>
                      </tr> -->
                    </tbody></table>
<br>
<hr>

<!--  Achievements  -->
<h3 class="mb-3">Achievements</h3>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Qualified GATE Computer Science in 2013, 2014.
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Qualified UGC-NET (Computer Science) in Dec 2018.
                    </li>
                    
                </ul>
<br><hr>

<!-- Professional Membership   -->
<h3 class="mb-3">Professional Membership</h3>
                <ul class="fa-ul mb-0">
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Student member of IEEE (Institute of Electrical and Electronics Engineers)
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Professional member of ACM (Association for Computing Machinery)
                    </li>
                    <li>
                        <span class="fa-li"><i class="fas fa-check"></i></span>
                        Associate member of IEI ( The Institution of Engineers (India) )
                    </li>
                </ul>
<br><hr>
<!-- </div> -->
<!-- Contact-->
<h3 class="mb-3" id="contact">Contact</h3>
                <p> <br>Yamagishi Lab <br> National Institute of Informatics 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430
 <br> Mail ID: madan@nii.ac.jp OR surbhi.19csz0011@iitrpr.ac.in</p>

        </div>  
        </section>
        <hr class="m-0" />



        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
